# -*- coding: utf-8 -*-
"""Detecting Fault in Credit Card.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/177Ar9WEmJ-5jmDM_tnFhDY7moCFtBIAW
"""

# Import the required libraries

import warnings
warnings.filterwarnings('ignore')
!pip install matplotlib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Data Collection and Cleaning

credit_card_data = pd.read_csv('creditcard.csv')

credit_card_data.head()

credit_card_data.isnull()

credit_card_data.describe()

credit_card_data.info()

credit_card_data.isna().sum()

credit_card_data.Class.value_counts()

credit_card_data.groupby('Class').mean()

# Average amount for respective CLass (No Fault and Fault)
credit_card_data.groupby('Class')['Amount'].mean()

# 77.232517 is avg mean amount of data lies in CLass 0(Normal Transaction)
# 96.609677 is avg amount of data lies in Class 1(Faulty transaction)

# 0->27725     1-> 93
# Above representation is highly imbalanced which leads to poor model performance.

# Normalising the data
normal_transaction = credit_card_data[credit_card_data.Class==0]
fault_transaction = credit_card_data[credit_card_data.Class==1]

normal_transaction.shape

fault_transaction.shape

normal_transaction = normal_transaction.sample(n = 93)

normal_transaction.shape

fault_transaction.shape

# Now both are same

new_dataset = pd.concat([normal_transaction,fault_transaction])

new_dataset.head()

new_dataset.tail()

# Data Analysis and Visualization

plt.figure(figsize=(4,3))
sns.histplot(data = new_dataset, x = 'Amount', bins= 20, color= 'Red')

plt.figure(figsize=(4,3))
sns.histplot(data = new_dataset, x = 'Time', color = 'blue', bins = 30,kde= True)

plt.figure(figsize=(4,3))
sns.countplot(data = new_dataset, x  = 'Class', width = 0.5)

new_dataset.groupby('Class')['Amount'].mean()

# Train-Test-Split, Hyper parametr tuning and Model Selection
X = new_dataset.drop(['Class'],axis = 'columns').values
y = new_dataset.Class

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)

X_train.shape

X_test.shape

model = LogisticRegression()
print(model.fit(X_train,y_train))

ypred = model.predict(X_test)
ypred

from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,ypred))

confusion_matrix(y_test,ypred)

# PREDICTIVE SYSTEM
input_data = X_test[12]
input_data

pred = model.predict([input_data])
if pred[0] ==1:
  print('It is faulty transaction')
else:
  print('It is Normal transaction')

y_test[12:13]

